{
  "train_losses": [
    0.07739206774616038,
    0.008930593711537713,
    0.005328231965237073,
    0.004001658125917031
  ],
  "val_losses": [
    0.008413853040004,
    0.004697781322768148,
    0.002917511837759589,
    0.0027466010619890116
  ],
  "learning_rates": [
    1e-05,
    1e-05,
    1e-05,
    1.0000000000000002e-06
  ],
  "train_metrics": [
    {
      "accuracy": 0.9084654501944361,
      "f1_score": 0.9267990014731671,
      "precision": 0.97320640951861,
      "recall": 0.885296512078488,
      "loss": 0.07739206774616038,
      "classification_report": {
        "legal_aid": {
          "precision": 0.9869253479544496,
          "recall": 0.9539339584182633,
          "f1-score": 0.9701492537313433,
          "support": 2453.0
        },
        "family_law": {
          "precision": 0.9543726235741445,
          "recall": 0.8408710217755444,
          "f1-score": 0.8940338379341051,
          "support": 597.0
        },
        "consumer_protection": {
          "precision": 0.9868554095045501,
          "recall": 0.9264356905552918,
          "f1-score": 0.9556915544675643,
          "support": 2107.0
        },
        "employment_law": {
          "precision": 0.9861878453038674,
          "recall": 0.8633615477629988,
          "f1-score": 0.9206963249516441,
          "support": 827.0
        },
        "fundamental_rights": {
          "precision": 0.9516908212560387,
          "recall": 0.8418803418803419,
          "f1-score": 0.8934240362811792,
          "support": 702.0
        },
        "micro avg": {
          "precision": 0.9805466237942122,
          "recall": 0.9122046066407419,
          "f1-score": 0.9451417945141795,
          "support": 6686.0
        },
        "macro avg": {
          "precision": 0.97320640951861,
          "recall": 0.885296512078488,
          "f1-score": 0.9267990014731671,
          "support": 6686.0
        },
        "weighted avg": {
          "precision": 0.9802059508256287,
          "recall": 0.9122046066407419,
          "f1-score": 0.9446239844626386,
          "support": 6686.0
        },
        "samples avg": {
          "precision": 0.9102602452886629,
          "recall": 0.9122046066407419,
          "f1-score": 0.9108834380297137,
          "support": 6686.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.008930593711537713,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2453.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 597.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2107.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 827.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 702.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 0.9998504337421478,
      "f1_score": 0.9999592252803261,
      "precision": 1.0,
      "recall": 0.9999184671830411,
      "loss": 0.005328231965237073,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 0.9995923359152059,
          "f1-score": 0.999796126401631,
          "support": 2453.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 597.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2107.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 827.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 702.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 0.9998504337421478,
          "f1-score": 0.9999252112781393,
          "support": 6686.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 0.9999184671830411,
          "f1-score": 0.9999592252803261,
          "support": 6686.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 0.9998504337421478,
          "f1-score": 0.9999252016247683,
          "support": 6686.0
        },
        "samples avg": {
          "precision": 0.9998504337421478,
          "recall": 0.9998504337421478,
          "f1-score": 0.9998504337421478,
          "support": 6686.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.004001658125917031,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2453.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 597.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2107.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 827.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 702.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        }
      },
      "confusion_matrix": null
    }
  ],
  "val_metrics": [
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.008413853040004,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 516.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 124.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 442.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 176.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 175.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.004697781322768148,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 516.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 124.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 442.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 176.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 175.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.002917511837759589,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 516.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 124.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 442.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 176.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 175.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.0027466010619890116,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 516.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 124.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 442.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 176.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 175.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        }
      },
      "confusion_matrix": null
    }
  ],
  "best_f1_score": 1.0,
  "final_epoch": 4,
  "model_config": {
    "model_name": "nlpaueb/legal-bert-base-uncased",
    "max_length": 256,
    "batch_size": 2,
    "learning_rate": 1e-05,
    "epochs": 15,
    "warmup_steps": 200,
    "weight_decay": 0.01,
    "dropout_prob": 0.3,
    "early_stopping_patience": 3,
    "gradient_clip_val": 1.0
  }
}