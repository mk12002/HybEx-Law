{
  "train_losses": [
    0.06566451568696642,
    0.008541531750598397,
    0.004996144945898283,
    0.0038015515039779707
  ],
  "val_losses": [
    0.008544213830249933,
    0.00473890192214178,
    0.0029225935199829966,
    0.0027577463119776396
  ],
  "learning_rates": [
    1e-05,
    1e-05,
    1e-05,
    1.0000000000000002e-06
  ],
  "train_metrics": [
    {
      "accuracy": 0.93351142772336,
      "f1_score": 0.9428053931962308,
      "precision": 0.9790442041629044,
      "recall": 0.9102443813024644,
      "loss": 0.06566451568696642,
      "classification_report": {
        "legal_aid": {
          "precision": 0.984928716904277,
          "recall": 0.9710843373493976,
          "f1-score": 0.9779575328614762,
          "support": 2490.0
        },
        "family_law": {
          "precision": 0.9659735349716446,
          "recall": 0.8690476190476191,
          "f1-score": 0.9149507609668756,
          "support": 588.0
        },
        "consumer_protection": {
          "precision": 0.9724770642201835,
          "recall": 0.9599618684461392,
          "f1-score": 0.9661789397937155,
          "support": 2098.0
        },
        "employment_law": {
          "precision": 0.9931506849315068,
          "recall": 0.8798543689320388,
          "f1-score": 0.9330759330759331,
          "support": 824.0
        },
        "fundamental_rights": {
          "precision": 0.9786910197869102,
          "recall": 0.8712737127371274,
          "f1-score": 0.9218637992831541,
          "support": 738.0
        },
        "micro avg": {
          "precision": 0.9796647004036013,
          "recall": 0.9366280795488275,
          "f1-score": 0.9576631259484066,
          "support": 6738.0
        },
        "macro avg": {
          "precision": 0.9790442041629044,
          "recall": 0.9102443813024644,
          "f1-score": 0.9428053931962308,
          "support": 6738.0
        },
        "weighted avg": {
          "precision": 0.9797197924273112,
          "recall": 0.9366280795488275,
          "f1-score": 0.9571592123310108,
          "support": 6738.0
        },
        "samples avg": {
          "precision": 0.9348224003166122,
          "recall": 0.9366280795488275,
          "f1-score": 0.9353270010883546,
          "support": 6738.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.008541531750598397,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2490.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 588.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2098.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 824.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 738.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.004996144945898283,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2490.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 588.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2098.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 824.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 738.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.0038015515039779707,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2490.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 588.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2098.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 824.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 738.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6738.0
        }
      },
      "confusion_matrix": null
    }
  ],
  "val_metrics": [
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.008544213830249933,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 522.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 129.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 475.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 160.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 159.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.00473890192214178,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 522.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 129.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 475.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 160.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 159.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.0029225935199829966,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 522.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 129.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 475.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 160.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 159.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.0027577463119776396,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 522.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 129.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 475.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 160.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 159.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1445.0
        }
      },
      "confusion_matrix": null
    }
  ],
  "best_f1_score": 1.0,
  "final_epoch": 4,
  "model_config": {
    "model_name": "nlpaueb/legal-bert-base-uncased",
    "max_length": 256,
    "batch_size": 2,
    "learning_rate": 1e-05,
    "epochs": 15,
    "warmup_steps": 200,
    "weight_decay": 0.01,
    "dropout_prob": 0.3,
    "early_stopping_patience": 3,
    "gradient_clip_val": 1.0
  }
}