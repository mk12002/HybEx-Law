{
  "train_losses": [
    0.07644311405705512,
    0.008769893268738393,
    0.005103985882831407,
    0.0039054431876342052
  ],
  "val_losses": [
    0.008244796778819676,
    0.004578915194736864,
    0.002823451201715916,
    0.0026611066571108196
  ],
  "learning_rates": [
    1e-05,
    1e-05,
    1e-05,
    1.0000000000000002e-06
  ],
  "train_metrics": [
    {
      "accuracy": 0.9157941968291954,
      "f1_score": 0.9327188726688744,
      "precision": 0.9712819033590984,
      "recall": 0.8981592486616226,
      "loss": 0.07644311405705512,
      "classification_report": {
        "legal_aid": {
          "precision": 0.9786789297658863,
          "recall": 0.9543416225030574,
          "f1-score": 0.9663570691434469,
          "support": 2453.0
        },
        "family_law": {
          "precision": 0.9683426443202979,
          "recall": 0.8710217755443886,
          "f1-score": 0.9171075837742504,
          "support": 597.0
        },
        "consumer_protection": {
          "precision": 0.9580520732883318,
          "recall": 0.943046986236355,
          "f1-score": 0.9504903133221717,
          "support": 2107.0
        },
        "employment_law": {
          "precision": 0.9824324324324324,
          "recall": 0.879081015719468,
          "f1-score": 0.9278876834716018,
          "support": 827.0
        },
        "fundamental_rights": {
          "precision": 0.9689034369885434,
          "recall": 0.8433048433048433,
          "f1-score": 0.9017517136329017,
          "support": 702.0
        },
        "micro avg": {
          "precision": 0.9705697198615045,
          "recall": 0.9223751121746934,
          "f1-score": 0.9458588957055215,
          "support": 6686.0
        },
        "macro avg": {
          "precision": 0.9712819033590984,
          "recall": 0.8981592486616226,
          "f1-score": 0.9327188726688744,
          "support": 6686.0
        },
        "weighted avg": {
          "precision": 0.9706936174365887,
          "recall": 0.9223751121746934,
          "f1-score": 0.9454177423711083,
          "support": 6686.0
        },
        "samples avg": {
          "precision": 0.9186484195832086,
          "recall": 0.9223751121746934,
          "f1-score": 0.9197377604945658,
          "support": 6686.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.008769893268738393,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2453.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 597.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2107.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 827.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 702.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.005103985882831407,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2453.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 597.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2107.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 827.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 702.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.0039054431876342052,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2453.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 597.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 2107.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 827.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 702.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 6686.0
        }
      },
      "confusion_matrix": null
    }
  ],
  "val_metrics": [
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.008244796778819676,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 516.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 124.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 442.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 176.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 175.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.004578915194736864,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 516.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 124.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 442.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 176.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 175.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.002823451201715916,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 516.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 124.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 442.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 176.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 175.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        }
      },
      "confusion_matrix": null
    },
    {
      "accuracy": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "loss": 0.0026611066571108196,
      "classification_report": {
        "legal_aid": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 516.0
        },
        "family_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 124.0
        },
        "consumer_protection": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 442.0
        },
        "employment_law": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 176.0
        },
        "fundamental_rights": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 175.0
        },
        "micro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "macro avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "weighted avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        },
        "samples avg": {
          "precision": 1.0,
          "recall": 1.0,
          "f1-score": 1.0,
          "support": 1433.0
        }
      },
      "confusion_matrix": null
    }
  ],
  "best_f1_score": 1.0,
  "final_epoch": 4,
  "model_config": {
    "model_name": "nlpaueb/legal-bert-base-uncased",
    "max_length": 256,
    "batch_size": 2,
    "learning_rate": 1e-05,
    "epochs": 15,
    "warmup_steps": 200,
    "weight_decay": 0.01,
    "dropout_prob": 0.3,
    "early_stopping_patience": 3,
    "gradient_clip_val": 1.0
  }
}